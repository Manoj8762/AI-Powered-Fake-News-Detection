ğŸ“° AI-Powered Fake News & Statement Verification System
ğŸ“Œ Project Overview

This project is an AI-driven web application designed to verify the factual correctness of user-provided statements. It intelligently combines Large Language Models (LLMs) with real-time news data to classify statements as REAL, FAKE, PARTIAL REAL, or PARTIAL FAKE, along with a deterministic confidence score.

The system is built to reduce hallucinations by validating claims against live external sources, making it suitable for misinformation detection, content moderation, and fact-checking use cases.

ğŸš€ Key Features

âœ… Verifies factual statements using multi-source AI reasoning

ğŸ§  Integrates OpenAI (ChatGPT) and Google Gemini

ğŸŒ Uses SerpAPI for real-time news validation

ğŸ§© Handles multiple statements in a single input

ğŸ“Š Provides consistent confidence scores for the same input

ğŸ–¥ï¸ Simple and interactive Flask-based web interface

ğŸ” Reproducible results using deterministic hashing

ğŸ› ï¸ Tech Stack

Backend: Python, Flask

Frontend: HTML, CSS

AI Models & APIs:

OpenAI (ChatGPT â€“ structured JSON responses)

Google Gemini (entity/person-based explanations)

SerpAPI (live Google News search)

Other: REST APIs, SHA-256 hashing, semantic analysis

ğŸ“‚ Project Structure
â”œâ”€â”€ app.py                 # Flask application entry point
â”œâ”€â”€ final9.py              # Core AI verification logic
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html         # Web UI
â”œâ”€â”€ static/
â”‚   â””â”€â”€ style.css          # Styling
â”œâ”€â”€ __pycache__/           # Compiled Python files

âš™ï¸ How the System Works
1ï¸âƒ£ User Input Processing

Accepts single or multiple statements

Supports comma-separated or line-separated inputs

2ï¸âƒ£ Intelligent Statement Routing

Person names detected â†’ Verified using Google Gemini

General claims detected â†’ Verified using:

SerpAPI (news headlines)

ChatGPT (structured factual explanation)

3ï¸âƒ£ Multi-Source Verification

Combines LLM reasoning with real-world evidence

Minimizes hallucination by grounding responses in live data

4ï¸âƒ£ Semantic Consistency Check

Detects contradictions or negations in explanations

Labels each statement as REAL or FAKE

5ï¸âƒ£ Aggregated Final Classification

REAL

FAKE

PARTIAL REAL

PARTIAL FAKE

6ï¸âƒ£ Deterministic Confidence Scoring

Uses SHA-256 hashing

Same input â†’ same confidence score

Ensures reproducibility and evaluation consistency

ğŸ“¤ Output Format

The system returns:

Final Result: PARTIAL REAL
Confidence Score: 0.72
Explanation: <Detailed factual explanations for each statement>

ğŸ” Environment Variables Required

Before running the project, set the following API keys:

export OPENAI_API_KEY="your_openai_api_key"
export GEMINI_API_KEY="your_gemini_api_key"
export SERPAPI_API_KEY="your_serpapi_key"

â–¶ï¸ How to Run the Application
1ï¸âƒ£ Install Dependencies
pip install flask openai google-generativeai requests

2ï¸âƒ£ Run the Flask App
python app.py

3ï¸âƒ£ Open Browser

The application automatically opens at:

http://127.0.0.1:5000/

ğŸ§ª Example Use Cases

Fake news detection

Social media content verification

Academic fact-checking tools

AI-assisted journalism

Misinformation monitoring systems

ğŸ“ˆ Future Enhancements

Confidence calibration using ground-truth datasets

Source credibility weighting

Multilingual fact verification

Database-backed verification history

Visualization dashboard for fact-checking results

ğŸ‘¨â€ğŸ’» Author

Manoj M J
Data Science & AI Enthusiast

â­ Acknowledgements

OpenAI

Google Gemini

SerpAPI
